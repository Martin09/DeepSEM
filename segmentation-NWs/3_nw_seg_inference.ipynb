{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NW Segmentation 3: Loading Trained Model and Inference",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Martin09/DeepSEM/blob/master/segmentation-NWs/3_nw_seg_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SMEbJUHYJh9",
        "colab_type": "text"
      },
      "source": [
        "# 3 - Model loading and NW size/yield analysis\n",
        "In this notebook we will:\n",
        "1. Load an image for analysis.\n",
        "2. Load our previously-trained model.\n",
        "3. Use model to label the SEM image.\n",
        "4. Perform post-processing on model output to learn about our NW distribution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDmXb0wNOyri",
        "colab_type": "text"
      },
      "source": [
        "Note: A GPU instance is not necessary for this notebook as we will only be performing inference which is not as computationally-expensive as training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII",
        "colab_type": "text"
      },
      "source": [
        "## Install detectron2\n",
        "Again, we will be using Facebook's [detectron2](https://github.com/facebookresearch/detectron2) library to run the interence on our images to let's install it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4hmGYk1dL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install detectron2:\n",
        "!pip install detectron2==0.1.2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger('logs')\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os, cv2, random, tifffile, json, datetime, time, urllib\n",
        "from glob import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "plt.rc('axes', axisbelow=True)\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7xOxlkQQ5LQ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# Define the classes in our dataset\n",
        "class_dict = {'droplet': '1',\n",
        "              'nanowire': '2',\n",
        "              'parasitic': '3'}\n",
        "\n",
        "# Define a dict that maps class number back to class name too\n",
        "inv_class_dict = dict(map(reversed, class_dict.items()))\n",
        "\n",
        "# Define some paths/constants that will be useful later\n",
        "desired_mag = 20000  # Used to filter the TIFF input files\n",
        "\n",
        "root = Path('./DeepSEM/segmentation-NWs/')\n",
        "dataset_dir = root.joinpath('datasets')\n",
        "output_dir = root.joinpath('output')\n",
        "models_dir = root.joinpath('trained_models')\n",
        "\n",
        "github_url = 'https://github.com/Martin09/' + str(root).replace('/','/trunk/')\n",
        "\n",
        "imgs_zip = dataset_dir.joinpath('WJ_NWs_D1-17-02-17-C_rawtiffs.zip')\n",
        "imgs_dir = dataset_dir.joinpath(imgs_zip.stem)\n",
        "\n",
        "test_dir = imgs_dir.joinpath('test')\n",
        "train_dir = imgs_dir.joinpath('train')\n",
        "\n",
        "dataset_root_name = 'nm_masks'\n",
        "train_name = dataset_root_name + '_train'\n",
        "test_name = dataset_root_name + '_test'\n",
        "\n",
        "model_path = models_dir.joinpath('nw_seg_it20k_loss0.027.yaml')\n",
        "weights_path = models_dir.joinpath('nw_seg_it20k_loss0.027.pth')\n",
        "\n",
        "weights_google_drive_id = '1CCV71LfnHGCz5JRe4RKw4k-Dm91IkEoF'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGJYcrPIRE3v",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 - Unpack and load our images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kufCnL8z-vZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Optional: Save everything to your own GoogleDrive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive/')\n",
        "# %cd \"/content/gdrive/My Drive/path/to/save/location\"\n",
        "\n",
        "# Clone just the relevant folder from the DeepSEM repo\n",
        "!rm -rf $root\n",
        "!apt install subversion\n",
        "!svn checkout $github_url $root\n",
        "\n",
        "# # Alternative: Clone whole DeepSEM repository\n",
        "# !rm -rf DeepSEM  # Remove folder if it already exists\n",
        "# !git clone https://github.com/Martin09/DeepSEM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FF1vtvEJtjK",
        "colab_type": "text"
      },
      "source": [
        "For simplicity, I will use our previous training images for inference. However these could be replaced with any similar un-labelled SEM images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YLhiiLbWRXQO",
        "colab": {}
      },
      "source": [
        "# Unzip raw dataset\n",
        "!rm -rf $imgs_dir\n",
        "!unzip -o $imgs_zip -d $imgs_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfnP9zJNNj1L",
        "colab_type": "text"
      },
      "source": [
        "We will sort the input files which have many different magnifications into images that only have the desired magnification (50k in this case)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq1AXXKkMG11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_files = list(imgs_dir.rglob('*.tif'))\n",
        "\n",
        "images = []\n",
        "# Start to loop over all TIFF files\n",
        "for file in in_files:\n",
        "    # Open each file using the TiffFile library\n",
        "    with tifffile.TiffFile(file) as tif:\n",
        "        \n",
        "        # Extract magnification data\n",
        "        mag = tif.sem_metadata['ap_mag'][1] \n",
        "        if type(mag) is str:  # Apply correction for \"k\" ex: mag = \"50 k\"\n",
        "            mag = float(mag.split(' ')[0]) * 1000\n",
        "        else:\n",
        "            mag = float(mag)\n",
        "\n",
        "        # Only filter the images that have the magnification that we are interested in\n",
        "        if not mag == desired_mag:\n",
        "          continue\n",
        "\n",
        "    images.append(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2KM5HQp4gHh",
        "colab_type": "text"
      },
      "source": [
        "Load a random image and show it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuFUcV5tq8Tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_path = random.sample(images,1)[0]\n",
        "im = cv2.imread(str(im_path), cv2.IMREAD_GRAYSCALE)\n",
        "print(im.shape)\n",
        "cv2_imshow(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szbPuPoKOKJR",
        "colab_type": "text"
      },
      "source": [
        "Do some pre-processing to get it ready to feed into our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYDE7vVMqq78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model expects an RGB image, so copy the greyscale data into other 2 channels\n",
        "im_RGB = np.repeat(im[:, :, np.newaxis], 3, axis=2)\n",
        "\n",
        "# Trim off the overlay bar at bottom of image\n",
        "im_RGB = im_RGB[:688,:]\n",
        "\n",
        "# Show the image\n",
        "print(im_RGB.shape)\n",
        "cv2_imshow(im_RGB)\n",
        "\n",
        "# For use later\n",
        "img_h = im_RGB.shape[0]\n",
        "img_w = im_RGB.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDEx09lYVyYE",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 - Load our model\n",
        "\n",
        "Now we will load a trained model and use it to label the above image. First we load a default config with `get_cfg()` and we then overwrite some of its parameters with our saved YAML configuration file. \n",
        "\n",
        "One important point is that we need to have `cfg.MODEL.WEIGHTS` set to point to the weights file. As this file can be quite big (>300MB) and since Github isn't designed to host big binary files, I have saved the weights for this model on my Google Drive instead. However, if you have your weights saved locally (ex: on your Google Drive), you can skip this download."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBQbpIgXTi9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if .zip file exists, if not, download it from Google Drive\n",
        "if weights_path.exists():\n",
        "  print('Dataset already exists. Skipping download!')\n",
        "else:\n",
        "  print('Dataset does not exist... Downloading!')\n",
        "  !gdown --id $weights_google_drive_id -O $weights_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRf9lQoyeIGg",
        "colab_type": "text"
      },
      "source": [
        "Now we can go ahead with the rest of the configuration of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLjc8j5wY7Yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_path)\n",
        "cfg.MODEL.WEIGHTS = str(weights_path)\n",
        "cfg.MODEL.DEVICE = 'cpu'  # CPU is enough for inference, no need for GPU\n",
        "\n",
        "# If we have a lot of objects to detect, need to set higher # of proposals here:\n",
        "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
        "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 2000\n",
        "cfg.TEST.DETECTIONS_PER_IMAGE = 200\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # Set the testing threshold for this model\n",
        "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.2     # Non-max supression threshold\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(class_dict) # We have three classification classes \n",
        "\n",
        "# Setting allowed input sizes (avoid scaling)\n",
        "cfg.INPUT.MIN_SIZE_TEST = 0\n",
        "cfg.INPUT.MAX_SIZE_TEST = 99999\n",
        "\n",
        "# A bit of a hacky way to be able to use the DefaultPredictor:\n",
        "# Register a \"fake\" dataset to then set the 'thing_classes' metadata\n",
        "# (there is probably a better way to do this...)\n",
        "cfg.DATASETS.TEST = ('placeholder')\n",
        "DatasetCatalog.clear()\n",
        "DatasetCatalog.register(\"placeholder\", lambda _: None)\n",
        "MetadataCatalog.get(\"placeholder\").set(thing_classes=list(class_dict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xCA0YZyssvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor = DefaultPredictor(cfg)\n",
        "outputs = predictor(im_RGB)\n",
        "print('Number of detected objects = {}'.format(len(outputs[\"instances\"])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE8ZPTc4yZAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verify outputs manually\n",
        "# outputs[\"instances\"].pred_classes\n",
        "# outputs[\"instances\"].pred_boxes\n",
        "# outputs[\"instances\"].scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLHfqmf1yesU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can use Visualizer to draw the predictions on the image.\n",
        "v = Visualizer(im_RGB[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TEST[0]), scale=1.5)\n",
        "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20XCitnL5F42",
        "colab_type": "text"
      },
      "source": [
        "## 3.4 - Post-processing model output\n",
        "\n",
        "However, just getting the output from the model isn't enough. Now we have to do bit more work to post-process the output and extract things like nanomembrane yield, sizes and other interesting data!\n",
        "\n",
        "First lets divide up the output of the neural net for further processing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQSzFCWmlLFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cl = np.array(outputs[\"instances\"].pred_classes.cpu())  # Classes\n",
        "s = np.array(outputs[\"instances\"].scores.cpu()) # Prediction scores\n",
        "b =  np.array([x.numpy() for x in outputs[\"instances\"].pred_boxes])  # Bounding boxes\n",
        "c = np.array(outputs[\"instances\"].pred_boxes.get_centers())  # Bounding box centres\n",
        "m =  np.array([x.numpy() for x in outputs[\"instances\"].pred_masks])  # Segmentation masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bUNMBtxEGhA",
        "colab_type": "text"
      },
      "source": [
        "Now we can loop over all the possible classes and display images with segmentation masks of each class individually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr_MzaJG5wQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for clas in range(len(class_dict)):\n",
        "  i_filt = list(np.argwhere(cl==clas).flatten()) # Choose only the indixes with specific class\n",
        "\n",
        "  print(f\"{inv_class_dict[str(clas+1)]}:\")\n",
        "\n",
        "  # We can use Visualizer to draw the predictions on the image.\n",
        "  v = Visualizer(im_RGB[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TEST[0]), scale=1.0)\n",
        "  v = v.draw_instance_predictions(outputs[\"instances\"][[i_filt]].to(\"cpu\"))\n",
        "  cv2_imshow(v.get_image()[:, :, ::-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrog16S9Eboh",
        "colab_type": "text"
      },
      "source": [
        "Now, before we can start to mess around with dimensional analysis we first need to extract the pixel size from the raw TIF image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SZ1Fff0OS3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tifffile.TiffFile(im_path) as tif:\n",
        "    \n",
        "    # Extract magnification data\n",
        "    mag = tif.sem_metadata['ap_mag'][1] \n",
        "    if type(mag) is str:  # Apply correction for \"k\" ex: mag = \"50 k\"\n",
        "        mag = float(mag.split(' ')[0]) * 1000\n",
        "    else:\n",
        "        mag = float(mag)\n",
        "\n",
        "    # Extract pixel size data\n",
        "    pixel_size = float(tif.sem_metadata['ap_pixel_size'][1])  # nm\n",
        "    if 'Âµm' in tif.sem_metadata['ap_pixel_size'][2]: # Correction for um\n",
        "        pixel_size *= 1000\n",
        "\n",
        "    # Extract tilt data\n",
        "    tilt = tif.sem_metadata['ap_stage_at_t'][1]  # degrees tilt\n",
        "\n",
        "pixel_size_x = pixel_size  # nm\n",
        "pixel_size_y = pixel_size / np.cos(np.deg2rad(tilt))  # nm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BfeJGkdJczU",
        "colab_type": "text"
      },
      "source": [
        "Let's put the output into a handy Pandas Dataframe before any more processing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuYsqm19M6Tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define data structure\n",
        "data = { 'class':[],\n",
        "         'class_num':[],\n",
        "         'score':[],\n",
        "         'bbox':[],\n",
        "         'bbox_centre':[],\n",
        "         'height':[],\n",
        "         'width':[],\n",
        "         'mask':[],\n",
        "         'area':[],\n",
        "         'area_bbox':[]}\n",
        "\n",
        "# Loop over all objects\n",
        "for i in range(len(outputs[\"instances\"])):\n",
        "  \n",
        "  data['class'].append(inv_class_dict[str(cl[i]+1)])\n",
        "  data['class_num'].append(cl[i])\n",
        "\n",
        "  data['score'].append(s[i])\n",
        "\n",
        "  data['bbox'].append(b[i])\n",
        "  data['bbox_centre'].append(c[i])\n",
        "\n",
        "  h = (b[i,3] - b[i,1]) * pixel_size_y\n",
        "  data['height'].append(h)\n",
        "\n",
        "  w = (b[i,2] - b[i,0]) * pixel_size_x  \n",
        "  data['width'].append(w)\n",
        "\n",
        "  data['area_bbox'].append(w*h)\n",
        "\n",
        "  data['mask'].append(m[i])\n",
        "\n",
        "  data['area'].append(m[i].astype(int).sum() * pixel_size_x * pixel_size_y)\n",
        "\n",
        "df = pd.DataFrame.from_dict(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4BcMaqhfm5m",
        "colab_type": "text"
      },
      "source": [
        "Let's plot a simple bar graph of the number of objects in each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZgtF8eIfzAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig_size = (8,6)\n",
        "\n",
        "fig = plt.figure(figsize=fig_size)\n",
        "\n",
        "counts = df['class'].value_counts()\n",
        "total = sum(counts)\n",
        "values = [cnt/total*100 for cnt in counts]\n",
        "labels = list(counts.index)\n",
        "\n",
        "sns.barplot(x=labels, y=values) # height should be three times width);\n",
        "\n",
        "for i, v in enumerate(values):\n",
        "    plt.text(i, v + np.max(values)*0.01, f'{v:.1f}% ({counts[i]:.0f})', color='k', ha='center')\n",
        "\n",
        "plt.ylim([0, np.max(values)*(1.1)])\n",
        "plt.title('Growth Structure Yield (count)')\n",
        "plt.ylabel('Yield (%)')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC76PV5POVec",
        "colab_type": "text"
      },
      "source": [
        "Let's start with nanowire length/width."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pYmcv1AAk4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_slits = df[df['class']=='nanowire']\n",
        "\n",
        "print(f\"Mean NW height: {df_slits['height'].mean():.0f} +/- {df_slits['height'].std():.0f} nm\")\n",
        "print(f\"Mean NW width: {df_slits['width'].mean():.0f} +/- {df_slits['width'].std():.0f} nm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANMtjwW3gOJ9",
        "colab_type": "text"
      },
      "source": [
        "Can do the same for the droplets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjkFHyuxgNw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_slits = df[df['class']=='droplet']\n",
        "\n",
        "print(f\"Mean droplet height: {df_slits['height'].mean():.0f} +/- {df_slits['height'].std():.0f} nm\")\n",
        "print(f\"Mean droplet width: {df_slits['width'].mean():.0f} +/- {df_slits['width'].std():.0f} nm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afiS3gpXh02M",
        "colab_type": "text"
      },
      "source": [
        "And also parasitic crystals/droplets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P87kuHbIh0Fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_slits = df[df['class']=='parasitic']\n",
        "\n",
        "print(f\"Mean parasitic height: {df_slits['height'].mean():.0f} +/- {df_slits['height'].std():.0f} nm\")\n",
        "print(f\"Mean parasitic width: {df_slits['width'].mean():.0f} +/- {df_slits['width'].std():.0f} nm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eP7FgTZdRrc",
        "colab_type": "text"
      },
      "source": [
        "We can then also plot a comparison of total area fraction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3wXa4N9dc2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_areas = []\n",
        "\n",
        "# Loop over all classes\n",
        "for clas in range(len(class_dict)):\n",
        "  \n",
        "  df_filt = df[df['class_num']==clas]\n",
        "\n",
        "  # There isn't any object with this class in the current image\n",
        "  if df_filt.size == 0:\n",
        "      print(f\"{inv_class_dict[str(clas+1)]} area: 0 nm2\")\n",
        "      class_areas.append(0)\n",
        "      continue\n",
        "\n",
        "  # Stack all masks in this class together\n",
        "  overall_mask = df_filt['mask'].sum()\n",
        "\n",
        "  # This approach avoids double counting pixels if masks overlap with eachother\n",
        "  overall_mask = overall_mask.astype(bool).astype(int)\n",
        "\n",
        "  # Calculate area\n",
        "  area = overall_mask.sum() * pixel_size_x * pixel_size_y\n",
        "  print(f\"{inv_class_dict[str(clas+1)]} area: {area:.0f} nm2\")\n",
        "  \n",
        "  # Add area to the areas list\n",
        "  class_areas.append(area)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tj73F-1kk79",
        "colab_type": "text"
      },
      "source": [
        "Now we can plot the total area of each class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xNvU3BgkJYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=fig_size)\n",
        "\n",
        "img_area = img_h * pixel_size_y * img_w * pixel_size_x\n",
        "\n",
        "values = [area/img_area*100 for area in class_areas]\n",
        "labels = [inv_class_dict[str(clas+1)] for clas in range(len(class_dict))]\n",
        "\n",
        "sns.barplot(x=labels, y=values)\n",
        "\n",
        "for i, v in enumerate(values):\n",
        "    plt.text(i, v + np.max(values)*0.01, f'{v:.1f}%\\n({class_areas[i]:.0f} nm$^2$)', color='k', ha='center')\n",
        "\n",
        "plt.ylim([0, np.max(values)*(1.1)])\n",
        "plt.title('Growth Structure Yield (% of image area)')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u0o3NxalsmE",
        "colab_type": "text"
      },
      "source": [
        "If we want to compare the dimensions of all classes we can define a handy plotting function that we then use to plot different values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvafpCirCpiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a helper function for easy box plotting\n",
        "def make_box_plot(dat, x, x_lab):\n",
        "  # Create figure\n",
        "  fig = plt.figure(figsize=fig_size)\n",
        "\n",
        "  # Plot the orbital period with horizontal boxes\n",
        "  ax = sns.boxplot(x=x, y='class', data=dat, whis=[0, 100], palette=\"vlag\")\n",
        "  ax.set(xlim=(0, dat[x].max()*1.2))\n",
        "  ax.xaxis.grid(True)\n",
        "\n",
        "  # Add in points to show each observation\n",
        "  g = sns.swarmplot(x=x, y='class', data=dat, size=5, color=\".3\", linewidth=0)\n",
        "\n",
        "  # Tweak the visual presentation\n",
        "  plt.xlabel(x_lab)\n",
        "  plt.ylabel(\"\")\n",
        "  title = x_lab.split(\" \")[0]\n",
        "  plt.title(f\"{title} Distributions\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLud1bn2iGQO",
        "colab_type": "text"
      },
      "source": [
        "Plotting height distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNMWym48DUgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove parasitic growth for the dimension analysis\n",
        "df_filt= df[df['class']!='parasitic']\n",
        "\n",
        "make_box_plot(df_filt,'height','Height (nm)');\n",
        "# NOTE: since we are looking at tilted SEM images, we can't distinguish between \n",
        "# crystals growing vertically or towards the top of the image but along the substrate \n",
        "\n",
        "# However, we know the NWs grow vertically, so calling this dimension \"height\" \n",
        "# is valid at least for the NWs.\n",
        "\n",
        "# TODO: Remove nanowires that are touching the borders of the image!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgiLyFHFiJlQ",
        "colab_type": "text"
      },
      "source": [
        "Plotting width distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUixzmyUaf2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_box_plot(df_filt,'width','Width (nm)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fetuqT0klQC",
        "colab_type": "text"
      },
      "source": [
        "Plotting area distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUblT0uZYEGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_box_plot(df_filt,'area','Area (nm$^2$)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcTnXUXFbV2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot a scatter plot of growth structure length vs width to try and see some trends\n",
        "fig = plt.figure(figsize=fig_size)\n",
        "ax = sns.scatterplot(x=\"width\", y=\"height\", hue=\"class\", style=\"class\", s=50, data=df_filt)\n",
        "ax.grid()\n",
        "ax.set(xlabel='Width (nm)')\n",
        "ax.set(ylabel='Height (nm)')\n",
        "ax.set(title='Width vs Height Plot');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4Eo0WLujQYz",
        "colab_type": "text"
      },
      "source": [
        "Going forward, there are still a lot of improvements that can be made to this relatively basic code. Things like model/hyperparameter refinements and model-assisted labelling to quickly grow the training set would be a nice next step!\n",
        "\n",
        "Anyways, that's it! I hope this tutorial was somewhat useful and that a few of you are able to use these scripts as a starting point to apply these techniques into your own work!"
      ]
    }
  ]
}
