{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_nw_yield-training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Martin09/DeepSEM/blob/master/nanowire_yield/2_nw_yield_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3WNX8GlYrw0",
        "colab_type": "text"
      },
      "source": [
        "# 2 - Model definition, training and saving\n",
        "In this notebook we will:\n",
        "1. Create a new model based on a pre-trained model from the detectron2 repository. \n",
        "2. Perform transfer learning to train it on our dataset of labelled SEM images. \n",
        "3. Do some quick inference to test our trained model.\n",
        "4. Save the model to a file for later use.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFmdTLrqZfr3",
        "colab_type": "text"
      },
      "source": [
        "First, let's check that we are running a GPU instance of Colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU5aaqXsKgU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime -> \"Change runtime type\" menu to enable GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIWV0OifHITX",
        "colab_type": "text"
      },
      "source": [
        "If you see a prompt above to \"Change runtime type\" then you are not running a GPU instance. Follow the instructions above to enable the GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII",
        "colab_type": "text"
      },
      "source": [
        "# Install detectron2\n",
        "We will be using Facebook's [detectron2](https://github.com/facebookresearch/detectron2) library to train our model. First we need to install it and its dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4hmGYk1dL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install detectron2:\n",
        "!pip install detectron2==0.1.2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, cv2, random, json\n",
        "from glob import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2bjrfb2LDeo",
        "colab_type": "text"
      },
      "source": [
        "# Train on a custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjbUIhSxUdm_",
        "colab_type": "text"
      },
      "source": [
        "In this section, we will train an existing detectron2 model on our labelled SEM image dataset.\n",
        "\n",
        "We use [a custom labelled nanowire detection dataset](https://github.com/Martin09/DeepSEM/tree/master/Datasets/NWs-8kMag-subdivided.zip)\n",
        "which has three classes: \n",
        "*   Nanowire\n",
        "*   Parasitic Growth\n",
        "*   Nanospade\n",
        "\n",
        "\n",
        "We'll train a custom object detection model from an existing model pre-trained on the COCO dataset, available in detectron2's model zoo.\n",
        "\n",
        "Note that the COCO dataset does not have any of these categories so we will have to perform transfer learning to get the model to detect them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFuJHciptkop",
        "colab_type": "text"
      },
      "source": [
        "## Prepare our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qg7zSVOulkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone the DeepSEM repository\n",
        "!rm -rf DeepSEM\n",
        "!git clone https://github.com/Martin09/DeepSEM\n",
        "\n",
        "# OR\n",
        "\n",
        "# # Load from my GoogleDrive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive/')\n",
        "# %cd \"/content/gdrive/My Drive/LMSC/MachineLearning/Colab\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKC6DyTaIELj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dir = './DeepSEM/nanowire_yield/datasets/NWs-8kMag-subdivided/'\n",
        "!wget https://github.com/Martin09/DeepSEM/raw/master/nanowire_yield/datasets/NWs-8kMag-subdivided.zip\n",
        "!unzip NWs-8kMag-subdivided.zip -d $dataset_dir\n",
        "!rm NWs-8kMag-subdivided.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk4gID50K03a",
        "colab_type": "text"
      },
      "source": [
        "## Calculate mean pixel intensity of dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IRGo8d0qkgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calcualte dataset mean pixel intensity\n",
        "images_dir = './DeepSEM/nanowire_yield/datasets/NWs-8kMag-subdivided/'\n",
        "images = glob(images_dir + '*.png')\n",
        "\n",
        "min_pixel_intensity = np.infty\n",
        "max_pixel_intensity = -np.infty\n",
        "mean_pixel_intensity = 0\n",
        "for img in images:\n",
        "    im = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
        "    min_pixel_intensity = min([np.min(im), min_pixel_intensity])\n",
        "    max_pixel_intensity = max([np.max(im), max_pixel_intensity])\n",
        "    mean_pixel_intensity += np.mean(im)\n",
        "mean_pixel_intensity /= len(images)\n",
        "\n",
        "print('The min pixel intesity is: {:.2f}'.format(min_pixel_intensity))\n",
        "print('The max pixel intesity is: {:.2f}'.format(max_pixel_intensity))\n",
        "print('The mean pixel intesity is: {:.2f}'.format(mean_pixel_intensity))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxxdIHv-Vzu8",
        "colab_type": "text"
      },
      "source": [
        "## Test/train Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCa0_cq3TjfC",
        "colab_type": "text"
      },
      "source": [
        "Our dataset consists of our subdivided PNG images in the folder:\n",
        "```\n",
        "./DeepSEM/nanowire_yield/datasets/NWs-8kMag-subdivided/\n",
        "```\n",
        "\n",
        "Along with our bounding box labels in the form of a labelbox JSON export file located at:\n",
        "```\n",
        "'./DeepSEM/nanowire_yield/datasets/export-2020-05-26T15_27_19.519Z.json'\n",
        "```\n",
        "\n",
        "Next, we will create a helper function to divide the exported JSON file into two smaller files: a training set and a test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZMtnLB_V2yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Takes a labelbox exported JSON file and randomly splits it into two other JSON files:\n",
        "# one for testing and one for validation. Assumes test set should be ~10% of all examples.\n",
        "def test_train_split(json_file, t_out = 'train.json', v_out = 'val.json'):\n",
        "    \n",
        "    # Load Labelbox export file\n",
        "    with open(json_file) as f:\n",
        "        dat = json.load(f)\n",
        "\n",
        "     # Remove empty entries   \n",
        "    dat = [d for d in dat if d[\"Label\"] != {}]  \n",
        "    \n",
        "    # Choose some indices at random for the test set, the rest are for training\n",
        "    i_test = np.random.choice(len(dat), int(len(dat)*0.1))\n",
        "    i_train = list(set(list(range(len(dat))))-set(i_test))\n",
        "\n",
        "    # Split the dataset according to the indices\n",
        "    dat_train = [dat[i] for i in i_train]\n",
        "    dat_test = [dat[i] for i in i_test]\n",
        "\n",
        "    # Write the train.json and val.json files\n",
        "    with open(t_out, 'w') as fout:\n",
        "        json.dump(dat_train, fout)\n",
        "    with open(v_out, 'w') as fout:\n",
        "        json.dump(dat_test, fout)      \n",
        "    \n",
        "    print(\"Exported {} training images and {} test images!\".format(len(i_train),len(i_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-_r3LxLUmad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_file = './DeepSEM/nanowire_yield/datasets/export-2020-05-26T15_27_19.519Z.json'\n",
        "train_out = './DeepSEM/nanowire_yield/datasets/NWs-8kMag-subdivided/nw_yield_train.json'\n",
        "test_out = './DeepSEM/nanowire_yield/datasets/NWs-8kMag-subdivided/nw_yield_test.json'\n",
        "test_train_split(json_file, train_out, test_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVJoOm6LVJwW",
        "colab_type": "text"
      },
      "source": [
        "Register the datasets to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n",
        "Here, the dataset is in its custom format, therefore we write a function to parse it and prepare it into detectron2's standard format. See the tutorial for more details.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIbAM2pv-urF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
        "# from detectron2.data.datasets import register_coco_instances\n",
        "# register_coco_instances(\"my_dataset_train\", {}, \"json_annotation_train.json\", \"path/to/image/dir\")\n",
        "# register_coco_instances(\"my_dataset_val\", {}, \"json_annotation_val.json\", \"path/to/image/dir\")\n",
        "\n",
        "from detectron2.structures import BoxMode\n",
        "\n",
        "# Takes in dataset JSON file and returns a list of dicts in detectron2 format for training\n",
        "def get_nw_dicts_from_labelbox(json_file):\n",
        "    category_dict = {'nw':0, 'parasitic':1, 'nanospade':2}\n",
        "\n",
        "    with open(images_dir + json_file) as f:\n",
        "        img_anns = json.load(f)\n",
        "\n",
        "    dataset_dicts = []\n",
        "    for idx,img in enumerate(img_anns):\n",
        "        filename = images_dir+'/'+img['External ID']\n",
        "        height, width = cv2.imread(filename).shape[:2]\n",
        "\n",
        "        record = {}\n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "\n",
        "        objs = []\n",
        "        for anno in img['Label']['objects']:\n",
        "            bb = anno['bbox']\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [bb['left'], bb['top'], bb['width'], bb['height']],\n",
        "                \"bbox_mode\": BoxMode.XYWH_ABS,\n",
        "                \"category_id\": category_dict[anno['value']],\n",
        "            }\n",
        "            objs.append(obj)\n",
        "\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpmcUJW7XnQL",
        "colab_type": "text"
      },
      "source": [
        "Now we register the datasets in detectron2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYvy9a7dTimK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "DatasetCatalog.clear()\n",
        "\n",
        "for d in [\"train\", \"test\"]:\n",
        "    DatasetCatalog.register(\"nw_yield_\" + d, lambda d=d: get_nw_dicts_from_labelbox(\"nw_yield_\" + d + \".json\"))\n",
        "    MetadataCatalog.get(\"nw_yield_\" + d).set(thing_classes=[\"nw\",\"parasitic\",\"nanospade\"])\n",
        "nanowire_metadata = MetadataCatalog.get(\"nw_yield_train\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ljbWTX0Wi8E",
        "colab_type": "text"
      },
      "source": [
        "To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkNbUzUOLYf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dicts = get_nw_dicts_from_labelbox(\"nw_yield_train.json\")\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=nanowire_metadata, scale=2.0)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqXIXXhW8dA",
        "colab_type": "text"
      },
      "source": [
        "## Train!\n",
        "\n",
        "Now, let's transfer learn a coco-pretrained R50-FPN Mask R-CNN model on our SEM dataset. It takes ~35 minutes to train 1000 iterations on Colab Pro's P100 GPUs and a bit longer on Colab's free K80 GPUs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7unkuuiqLdqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "import datetime\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "output_dir = './DeepSEM/nanowire_yield/output/' + timestamp\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.OUTPUT_DIR = output_dir\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"nw_yield_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 16\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 16\n",
        "cfg.SOLVER.BASE_LR = 0.01  # learning rate\n",
        "cfg.SOLVER.MAX_ITER = 100  # 1000 is decent for initial testing, can do 10k-20k for the final model\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 10000  # Save a checkpoint after every this number of iterations\n",
        "\n",
        "# Learning rate warmup and decay\n",
        "cfg.SOLVER.WARMUP_FACTOR = 1/1000.  # Learning starts at BASE_LR * WU_FACTOR\n",
        "cfg.SOLVER.WARMUP_ITERS = 1000  # Number of iterations for warm-up phase\n",
        "cfg.SOLVER.WARMUP_METHOD = \"linear\"\n",
        "cfg.SOLVER.GAMMA = 0.5\n",
        "# cfg.SOLVER.STEPS = (100,200,300,)  # List of iteration numbers at which to decrease learning rate by factor GAMMA.\n",
        "cfg.SOLVER.STEPS = tuple(range(0,cfg.SOLVER.MAX_ITER,1000))\n",
        "\n",
        "# Validation set\n",
        "cfg.TEST.EVAL_PERIOD = 0\n",
        "cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n",
        "\n",
        "# Don't scale the input images\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = (0,)  # Keep these data types or might run into issues during inference when loading config file\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = 99999  # Keep these data types or might run into issues during inference when loading config file\n",
        "\n",
        "cfg.MODEL.RPN.IN_FEATURES = ['p2', 'p2', 'p3', 'p4', 'p5', 'p6']\n",
        "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.25, 0.5, 1.0, 2.0, 4.0, 8.0]]\n",
        "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[4], [8], [16], [32], [64], [128]]\n",
        "cfg.MODEL.PIXEL_MEAN = [58.33, 58.33, 58.33] \n",
        "cfg.MODEL.PIXEL_STD = [1.0, 1.0, 1.0]\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 4096\n",
        "cfg.MODEL.ROI_HEADS.POSITIVE_FRACTION = 0.5\n",
        "cfg.MODEL.ROI_HEADS.IOU_THRESHOLDS = [0.5] # Intersection over union threshold\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 # We have three classification classes \n",
        "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 4000\n",
        "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 4000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdRglxBzdvel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "# %reload_ext tensorboard\n",
        "%tensorboard --logdir ./DeepSEM/nanowire_yield/output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y11fbM2XDCFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start training\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS734GdaZhyT",
        "colab_type": "text"
      },
      "source": [
        "Hopefully, during training you should start to see the \"total_loss\" decreasing over time as the model learns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4vdDIOXyxF",
        "colab_type": "text"
      },
      "source": [
        "## Inference & evaluation using the trained model\n",
        "Now, let's run inference with the trained model on test dataset. First, let's create a predictor using the model we just trained:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya5nEuMELeq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # Set the testing threshold for this model\n",
        "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.2     # Non-max supression threshold\n",
        "cfg.DATASETS.TEST = (\"nw_yield_test\", )\n",
        "cfg.TEST.DETECTIONS_PER_IMAGE = 200\n",
        "cfg.INPUT.MIN_SIZE_TEST = 0\n",
        "cfg.INPUT.MAX_SIZE_TEST = 99999\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWq1XHfDWiXO",
        "colab_type": "text"
      },
      "source": [
        "Then, we randomly select several samples to visualize the prediction results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5LhISJqWXgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = get_nw_dicts_from_labelbox(\"nw_yield_test.json\")\n",
        "for d in random.sample(dataset_dicts, 3):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=nanowire_metadata, \n",
        "                   scale=2.0, \n",
        "                  #  instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpusgzC6HP_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Check the outputs of the neural network manually:\n",
        "# outputs[\"instances\"].pred_boxes\n",
        "# outputs[\"instances\"].scores\n",
        "# outputs[\"instances\"].pred_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkAjalDpa6na",
        "colab_type": "text"
      },
      "source": [
        "Now let's save our final model for safe keeping. We will use this model in the next notebook for inference on a full-scale SEM image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RuMV3d3a5pC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_source = cfg.OUTPUT_DIR + '/model_final.pth'\n",
        "model_name = 'nw_yield_it'+str(trainer.iter)+'_loss0.93.yaml'\n",
        "model_dest = './DeepSEM/nanowire_yield/trained_models/' + model_name\n",
        "\n",
        "# Move weights file to \"trained_models\" folder and update the config file accordingly\n",
        "weights_dest = model_dest[:-5] + '.pth'\n",
        "!cp $weights_source $weights_dest\n",
        "cfg.MODEL.WEIGHTS = weights_dest\n",
        "\n",
        "# Save the config file alongside the weights file\n",
        "confi_dest = model_dest\n",
        "with open(confi_dest, \"w\") as text_file:\n",
        "    text_file.write(cfg.dump())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kblA1IyFvWbT",
        "colab_type": "text"
      },
      "source": [
        "We can also evaluate its performance using AP metric implemented in COCO API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9tECBQCvMv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ## Not working yet, probably don't have dataset in proper COCO format\n",
        "# from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "# from detectron2.data import build_detection_test_loader\n",
        "# evaluator = COCOEvaluator(\"nw_yield_train\", cfg, False)#, output_dir=\"./output/\")\n",
        "# val_loader = build_detection_test_loader(cfg, \"nw_yield_train\")\n",
        "# inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "# # another equivalent way is to use trainer.test"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}