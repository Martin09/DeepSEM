{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NM Segmentation 1: Image Preparation",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Martin09/DeepSEM/blob/master/segmentation-NMs/1_nm_seg_image_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHnVupBBn9eR",
        "colab_type": "text"
      },
      "source": [
        "# NM Segmentation 1: Image Preparation\n",
        "In this notebook we will:\n",
        "1. Import our raw SEM images.\n",
        "2. Filter these based on magnification.\n",
        "3. Export desired images as PNGs.\n",
        "3. Upload images for labelling to a new [Labelbox](https://labelbox.com/) project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-G-JOO5twqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A few useful imports\n",
        "from matplotlib import pyplot as plt\n",
        "import shutil, os, random, cv2, tifffile, collections\n",
        "from pathlib import Path\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P__pcddllwj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define some paths that will be useful later\n",
        "root = Path('./DeepSEM/segmentation-NMs/')\n",
        "dataset_dir = root.joinpath('datasets')\n",
        "github_url = 'https://github.com/Martin09/' + str(root).replace('/','/trunk/')\n",
        "\n",
        "raw_zip = dataset_dir.joinpath('Nick_NMs_allrawimgs.zip')\n",
        "raw_dir = dataset_dir.joinpath(raw_zip.stem)\n",
        "out_dir = dataset_dir.joinpath('Nick_NMs_50kmag_png')\n",
        "upload_dir = out_dir  # We will upload the output imgs to LabelBox at the end"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFuJHciptkop",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 - Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qg7zSVOulkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Optional: Save everything to your own GoogleDrive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive/')\n",
        "# %cd \"/content/gdrive/My Drive/path/to/save/location\"\n",
        "\n",
        "# Clone just the relevant folder from the DeepSEM repo\n",
        "!rm -rf $root\n",
        "!apt install subversion\n",
        "!svn checkout $github_url $root\n",
        "\n",
        "# # Alternative: Clone whole DeepSEM repository\n",
        "# !rm -rf DeepSEM  # Remove folder if it already exists\n",
        "# !git clone https://github.com/Martin09/DeepSEM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_fjSfYAsw7F",
        "colab_type": "text"
      },
      "source": [
        "Now we will download ALL the SEM images for the analysis. Since this is a big .zip file, I have to host it on my Google Drive (Github won't let me). Here we will download and unzip the raw SEM images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZmNheg9dyd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if .zip file exists, if not, download it from Google Drive\n",
        "file_id = '1M2_0GLScsNY53w8hU2xJdXtisESfkOqI'\n",
        "if raw_zip.exists():\n",
        "  print('Dataset already exists. Skipping download!')\n",
        "else:\n",
        "  print('Dataset does not exist... Downloading!')\n",
        "  !gdown --id $file_id -O $raw_zip\n",
        "\n",
        "# Unzip raw dataset\n",
        "!rm -rf $raw_dir\n",
        "!unzip -o $raw_zip -d $raw_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFQGs4InqI0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a list of all TIFF files in the SEM image dataset\n",
        "in_files = list(raw_dir.rglob('*.tif'))\n",
        "print(\"Loaded {:.0f} SEM images.\".format(len(in_files)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXDeZn811Dwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sample and display a few of them to see what they look like\n",
        "for img_file in random.choices(in_files, k=3):\n",
        "    print(str(img_file) + \":\")\n",
        "    im = cv2.imread(str(img_file), cv2.IMREAD_GRAYSCALE)\n",
        "    cv2_imshow(im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avvLm0GE2qQm",
        "colab_type": "text"
      },
      "source": [
        "Notice the SEM images are of many different magnifications. Should filter these down to a single magnification before building our training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbStxAZh2_2I",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 - Filtering images by magnification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg3_gcM1hkSY",
        "colab_type": "text"
      },
      "source": [
        "First, let's just extract the magnification, pixel size and tilt of each image using a handy TIFF library to extract the metadata."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25Cz3zAI3ZlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mags = []  # Empty list to save magnifications\n",
        "\n",
        "# Start to loop over all TIFF files\n",
        "for file in in_files:\n",
        "    # Open each file using the TiffFile library\n",
        "    with tifffile.TiffFile(file) as tif:\n",
        "        \n",
        "        # Extract magnification data\n",
        "        mag = tif.sem_metadata['ap_mag'][1] \n",
        "        if type(mag) is str:  # Apply correction for \"k\" ex: mag = \"50 k\"\n",
        "            mag = float(mag.split(' ')[0]) * 1000\n",
        "        else:\n",
        "            mag = float(mag)\n",
        "\n",
        "        # Extract pixel size data\n",
        "        pixel_size = float(tif.sem_metadata['ap_pixel_size'][1])  # nm\n",
        "        if 'µm' in tif.sem_metadata['ap_pixel_size'][2]: # Correction for um\n",
        "            pixel_size *= 1000\n",
        "\n",
        "        # Extract tilt data\n",
        "        tilt = tif.sem_metadata['ap_tilt_angle'][1] # degrees\n",
        "#         tilt = tif.sem_metadata['ap_stage_at_t'][1]  # might be equivalent, not sure\n",
        "\n",
        "    print(f'mag = {mag:6.0f}x, \\tpixel_size = {pixel_size:4.0f} nm, \\ttilt = {tilt:2.0f}°')\n",
        "    mags.append(mag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvzgkA2xM_2l",
        "colab_type": "text"
      },
      "source": [
        "Above, we have printed the raw aquisition information of each image. In this format it is a bit difficult to visualize so let's put this into a histogram."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eVyXc-aMJTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_ = plt.hist(mags,bins=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUHpFz1tOQtX",
        "colab_type": "text"
      },
      "source": [
        "More explicitly, we can also count the number of images for each magnification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Km6VtiOKv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict(collections.Counter(mags))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36VTZWXHOalb",
        "colab_type": "text"
      },
      "source": [
        "It looks like 50k magnification would be the best for accurate segmentation as its the highest resolution for which we have a decent number of images. We have 20 images at this magnification so let's filter these out!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9snpwKxLHdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "desired_mag = 50000  # Magnification to filter the images by\n",
        "\n",
        "filt_imgs = []  # Declare empty list to collect the filtered 50k mag images\n",
        "for (img_file, img_mag) in zip(in_files, mags):\n",
        "  if int(img_mag) == desired_mag:\n",
        "    filt_imgs.append(img_file)\n",
        "\n",
        "print(f'Found {len(filt_imgs):.0f} images with mag of {desired_mag}!') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so3v__wmZe0W",
        "colab_type": "text"
      },
      "source": [
        "Let's look at a few of the filtered images to make sure our script worked as expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiXWToTsPxmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sample and display a few of them to see what they look like\n",
        "for img_file in random.choices(filt_imgs, k=3):\n",
        "    print(str(img_file) + \":\")\n",
        "    im = cv2.imread(str(img_file), cv2.IMREAD_GRAYSCALE)\n",
        "    cv2_imshow(im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXhjacVvaC6d",
        "colab_type": "text"
      },
      "source": [
        "Seems reasonable!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFLPFKsnvCK8",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 - Export as PNGs\n",
        "Next we will import the filtered TIFF images and export them as PNG files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPND0bPjvVWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the output directory\n",
        "!rm -rf $out_dir\n",
        "!mkdir $out_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw4wkOXStcQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loop over the filtered TIFF files\n",
        "for img_file in filt_imgs:\n",
        "    img = cv2.imread(str(img_file), cv2.IMREAD_GRAYSCALE) # Import the image\n",
        "\n",
        "    # Save as PNG file (replace spaces with underscores)\n",
        "    filename = out_dir.joinpath(str(img_file.stem).replace(\" \",\"_\") + '.png')\n",
        "    print(filename)\n",
        "\n",
        "    success = cv2.imwrite(str(filename), (img).astype('uint8')) # Save divided image as PNG\n",
        "\n",
        "    if not success:\n",
        "        print(f\"Error, couldn't write image '{filename}'\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2jba9xAciCj",
        "colab_type": "text"
      },
      "source": [
        "Optionally, we can now download the dataset for safe keeping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTFhn2GhBhTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # To download the dataset, if you want\n",
        "# from google.colab import files\n",
        "# %cd $out_dir\n",
        "# !rm -f ../dataset.zip\n",
        "# !zip -r ../dataset.zip *\n",
        "# files.download(\"../dataset.zip\")\n",
        "# %cd /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzGgQc2q-5HC",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 - Upload images for labeling\n",
        "Now we are ready to label these images for training the neural network. There are many tools available for creating labelled datasets. In this tutorial I will be using [Labelbox](https://labelbox.com/) for this purpose. \n",
        "\n",
        "Note: for those that don't care about labelling their own dataset, you can skip ahead to [Notebook 2](https://colab.research.google.com/github/Martin09/DeepSEM/blob/master/nanowire_yield/2_nw_yield_training.ipynb) where I will provide the pre-labelled data for the next steps.\n",
        "\n",
        "Moving on, let's install the labelbox API first:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axaCMz2I-vZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install labelbox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL4hsHAwBaph",
        "colab_type": "text"
      },
      "source": [
        "If you haven't already done so, go ahead and make a free Labelbox account. You can either upload your images to be labelled manually, or you can upload them directly using this script below. \n",
        "\n",
        "***If you want to upload the images from this script, you need to create an API key [here](https://app.labelbox.com/account/api-keys) and paste it below:***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HC1E-9yBvK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "API_KEY = '[INSERT LABELBOX API KEY HERE]'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAxyef1lBw2V",
        "colab_type": "text"
      },
      "source": [
        "Now we can make a new Labelbox project and a new dataset before uploading the sub-divided images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrziJJ4g-2YG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change these names if you wish\n",
        "project_name = 'NanomembraneSegmentation'\n",
        "dataset_name = 'Nick_NMs_50kmag'\n",
        "\n",
        "# Create a new project and dataset in Labelbox\n",
        "from labelbox import Client\n",
        "client = Client(API_KEY)\n",
        "project = client.create_project(name=project_name)\n",
        "dataset = client.create_dataset(name=dataset_name, projects=project)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UtLh1HiBEFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform a bulk upload of the PNG files\n",
        "dataset_files = list(upload_dir.glob('*.png'))  # Get a list of the files to upload\n",
        "dataset_files = [str(file) for fil in dataset_files]  # Convert to list of strings (not Paths)\n",
        "dataset.create_data_rows(dataset_files) # Upload the files\n",
        "print(\"Done!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPTKARhnD5sf",
        "colab_type": "text"
      },
      "source": [
        "After a few minutes, you should see the new project and images appear in your\n",
        "Labelbox account, [here](https://app.labelbox.com/projects). You can now finish setting up your Labelbox project on the website, including setting your object classes.\n",
        "\n",
        "For this tutorial, we will be doing segmentation. Therefore, be sure to ***only*** define segmentation objects (not bounding box or polygon objects, for example).\n",
        "\n",
        "[Notebook 2](https://colab.research.google.com/github/Martin09/DeepSEM/blob/master/segmentation-NMs/2_nm_seg_training.ipynb) assumes you have finished your labelling and have exported a labelbox .JSON file with all of your segmentation mask labels. If you don't have your own labelled dataset don't worry, I will provide that for you. See you there!"
      ]
    }
  ]
}