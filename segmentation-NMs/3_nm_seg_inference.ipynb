{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NM Segmentation 3: Loading Trained Model and Inference",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Martin09/DeepSEM/blob/master/segmentation-NMs/3_nm_seg_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SMEbJUHYJh9",
        "colab_type": "text"
      },
      "source": [
        "# 3 - Model loading and NM size/yield analysis\n",
        "In this notebook we will:\n",
        "1. Load an image for analysis.\n",
        "2. Load our previously-trained model.\n",
        "3. Use model to label the SEM image.\n",
        "4. Perform post-processing on model output to learn about our NM characteristics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDmXb0wNOyri",
        "colab_type": "text"
      },
      "source": [
        "Note: A GPU instance is not necessary for this notebook as we will only be performing inference which is not as computationally-expensive as training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII",
        "colab_type": "text"
      },
      "source": [
        "## Install detectron2\n",
        "Again, we will be using Facebook's [detectron2](https://github.com/facebookresearch/detectron2) library to run the interence on our images to let's install it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4hmGYk1dL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install detectron2:\n",
        "!pip install detectron2==0.1.2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger('logs')\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os, cv2, random, tifffile, json, datetime, time, urllib\n",
        "from glob import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "plt.rc('axes', axisbelow=True)\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7xOxlkQQ5LQ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# Define the classes in our dataset\n",
        "class_dict = {'slit': '1',\n",
        "              'nanomembrane': '2',\n",
        "              'parasitic': '3',\n",
        "              'bottom_nucleus': '4',\n",
        "              'side_nucleus': '5',\n",
        "              'nanowire': '6',\n",
        "              'overgrowth': '7'}\n",
        "\n",
        "# Define a dict that maps class number back to class name too\n",
        "inv_class_dict = dict(map(reversed, class_dict.items()))\n",
        "\n",
        "# Define some paths/constants that will be useful later\n",
        "desired_mag = 50000  # Used to filter the TIFF input files\n",
        "\n",
        "root = Path('./DeepSEM/segmentation-NMs/')\n",
        "dataset_dir = root.joinpath('datasets')\n",
        "output_dir = root.joinpath('output')\n",
        "models_dir = root.joinpath('trained_models')\n",
        "\n",
        "github_url = 'https://github.com/Martin09/' + str(root).replace('/','/trunk/')\n",
        "\n",
        "imgs_zip = dataset_dir.joinpath('Nick_NMs_allrawimgs.zip')\n",
        "imgs_dir = dataset_dir.joinpath(imgs_zip.stem)\n",
        "imgs_google_drive_id = '1M2_0GLScsNY53w8hU2xJdXtisESfkOqI'\n",
        "\n",
        "test_dir = imgs_dir.joinpath('test')\n",
        "train_dir = imgs_dir.joinpath('train')\n",
        "\n",
        "dataset_root_name = 'nm_masks'\n",
        "train_name = dataset_root_name + '_train'\n",
        "test_name = dataset_root_name + '_test'\n",
        "\n",
        "model_path = models_dir.joinpath('nm_seg_it20k_loss0.028.yaml')\n",
        "weights_path = models_dir.joinpath('nm_seg_it20k_loss0.028.pth')\n",
        "\n",
        "weights_google_drive_id = '1btMy-EyU2sTSSPQk8kf663DYgO-sD3kR'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGJYcrPIRE3v",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 - Unpack and load our images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kufCnL8z-vZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Optional: Save everything to your own GoogleDrive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive/')\n",
        "# %cd \"/content/gdrive/My Drive/path/to/save/location\"\n",
        "\n",
        "# Clone just the relevant folder from the DeepSEM repo\n",
        "!rm -rf $root\n",
        "!apt install subversion\n",
        "!svn checkout $github_url $root\n",
        "\n",
        "# # Alternative: Clone whole DeepSEM repository\n",
        "# !rm -rf DeepSEM  # Remove folder if it already exists\n",
        "# !git clone https://github.com/Martin09/DeepSEM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FF1vtvEJtjK",
        "colab_type": "text"
      },
      "source": [
        "For simplicity, I will use our previous training images for inference. However these could be replaced with any similar un-labelled SEM images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YLhiiLbWRXQO",
        "colab": {}
      },
      "source": [
        "# Check if .zip file exists, if not, download it from Google Drive\n",
        "if imgs_zip.exists():\n",
        "  print('Dataset already exists. Skipping download!')\n",
        "else:\n",
        "  print('Dataset does not exist... Downloading!')\n",
        "  !gdown --id $imgs_google_drive_id -O $imgs_zip\n",
        "\n",
        "# Unzip raw dataset\n",
        "!rm -rf $imgs_dir\n",
        "!unzip -o $imgs_zip -d $imgs_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfnP9zJNNj1L",
        "colab_type": "text"
      },
      "source": [
        "Now we will sort the input files which have many different magnifications into images that only have the desired magnification (50k in this case)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq1AXXKkMG11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_files = list(imgs_dir.rglob('*.tif'))\n",
        "\n",
        "images = []\n",
        "# Start to loop over all TIFF files\n",
        "for file in in_files:\n",
        "    # Open each file using the TiffFile library\n",
        "    with tifffile.TiffFile(file) as tif:\n",
        "        \n",
        "        # Extract magnification data\n",
        "        mag = tif.sem_metadata['ap_mag'][1] \n",
        "        if type(mag) is str:  # Apply correction for \"k\" ex: mag = \"50 k\"\n",
        "            mag = float(mag.split(' ')[0]) * 1000\n",
        "        else:\n",
        "            mag = float(mag)\n",
        "\n",
        "        # Only filter the images that have the magnification that we are interested in\n",
        "        if not mag == desired_mag:\n",
        "          continue\n",
        "\n",
        "    images.append(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2KM5HQp4gHh",
        "colab_type": "text"
      },
      "source": [
        "Load a random image and show it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuFUcV5tq8Tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_path = random.sample(images,1)[0]\n",
        "im = cv2.imread(str(im_path), cv2.IMREAD_GRAYSCALE)\n",
        "print(im.shape)\n",
        "cv2_imshow(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szbPuPoKOKJR",
        "colab_type": "text"
      },
      "source": [
        "Do some pre-processing to get it ready to feed into our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYDE7vVMqq78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model expects an RGB image, so copy the greyscale data into other 2 channels\n",
        "im_RGB = np.repeat(im[:, :, np.newaxis], 3, axis=2)\n",
        "print(im_RGB.shape)\n",
        "cv2_imshow(im_RGB)\n",
        "\n",
        "# For use later\n",
        "img_h = im_RGB.shape[0]\n",
        "img_w = im_RGB.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDEx09lYVyYE",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 - Load our model\n",
        "\n",
        "Now we will load a trained model and use it to label the above image. First we load a default config with `get_cfg()` and we then overwrite some of its parameters with our saved YAML configuration file. \n",
        "\n",
        "One important point is that we need to have `cfg.MODEL.WEIGHTS` set to point to the weights file. As this file can be quite big (>300MB) and since Github isn't designed to host big binary files, I have saved the weights for this model on my Google Drive instead. However, if you have your weights saved locally (ex: on your Google Drive), you can skip this download."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBQbpIgXTi9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if .zip file exists, if not, download it from Google Drive\n",
        "if weights_path.exists():\n",
        "  print('Dataset already exists. Skipping download!')\n",
        "else:\n",
        "  print('Dataset does not exist... Downloading!')\n",
        "  !gdown --id $weights_google_drive_id -O $weights_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRf9lQoyeIGg",
        "colab_type": "text"
      },
      "source": [
        "Now we can go ahead with the rest of the configuration of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLjc8j5wY7Yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_path)\n",
        "cfg.MODEL.WEIGHTS = str(weights_path)\n",
        "cfg.MODEL.DEVICE = 'cpu'  # CPU is enough for inference, no need for GPU\n",
        "\n",
        "# If we have a lot of objects to detect, need to set higher # of proposals here:\n",
        "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 1000\n",
        "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 1000\n",
        "cfg.TEST.DETECTIONS_PER_IMAGE = 200\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # Set the testing threshold for this model\n",
        "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.2     # Non-max supression threshold\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(class_dict) # We have three classification classes \n",
        "\n",
        "# Setting allowed input sizes (avoid scaling)\n",
        "cfg.INPUT.MIN_SIZE_TEST = 0\n",
        "cfg.INPUT.MAX_SIZE_TEST = 99999\n",
        "\n",
        "\n",
        "# A bit of a hacky way to be able to use the DefaultPredictor:\n",
        "# Register a \"fake\" dataset to then set the 'thing_classes' metadata\n",
        "# (there is probably a better way to do this...)\n",
        "cfg.DATASETS.TEST = ('placeholder')\n",
        "DatasetCatalog.clear()\n",
        "DatasetCatalog.register(\"placeholder\", lambda _: None)\n",
        "MetadataCatalog.get(\"placeholder\").set(thing_classes=list(class_dict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xCA0YZyssvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor = DefaultPredictor(cfg)\n",
        "outputs = predictor(im_RGB)\n",
        "print('Number of detected objects = {}'.format(len(outputs[\"instances\"])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE8ZPTc4yZAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verify outputs manually\n",
        "# outputs[\"instances\"].pred_classes\n",
        "# outputs[\"instances\"].pred_boxes\n",
        "# outputs[\"instances\"].scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLHfqmf1yesU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can use Visualizer to draw the predictions on the image.\n",
        "v = Visualizer(im_RGB[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TEST[0]), scale=1.5)\n",
        "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20XCitnL5F42",
        "colab_type": "text"
      },
      "source": [
        "## 3.4 - Post-processing model output\n",
        "\n",
        "However, just getting the output from the model isn't enough. Now we have to do bit more work to post-process the output and extract things like nanomembrane yield, sizes and other interesting data!\n",
        "\n",
        "First lets divide up the output of the neural net for further processing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQSzFCWmlLFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cl = np.array(outputs[\"instances\"].pred_classes.cpu())  # Classes\n",
        "s = np.array(outputs[\"instances\"].scores.cpu()) # Prediction scores\n",
        "b =  np.array([x.numpy() for x in outputs[\"instances\"].pred_boxes])  # Bounding boxes\n",
        "c = np.array(outputs[\"instances\"].pred_boxes.get_centers())  # Bounding box centres\n",
        "m =  np.array([x.numpy() for x in outputs[\"instances\"].pred_masks])  # Segmentation masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bUNMBtxEGhA",
        "colab_type": "text"
      },
      "source": [
        "Now we can loop over all the possible classes and display images with segmentation masks of each class individually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr_MzaJG5wQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for clas in range(len(class_dict)):\n",
        "  i_filt = list(np.argwhere(cl==clas).flatten()) # Choose only the indixes with specific class\n",
        "\n",
        "  print(f\"{inv_class_dict[str(clas+1)]}:\")\n",
        "\n",
        "  # We can use Visualizer to draw the predictions on the image.\n",
        "  v = Visualizer(im_RGB[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TEST[0]), scale=1.0)\n",
        "  v = v.draw_instance_predictions(outputs[\"instances\"][[i_filt]].to(\"cpu\"))\n",
        "  cv2_imshow(v.get_image()[:, :, ::-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrog16S9Eboh",
        "colab_type": "text"
      },
      "source": [
        "Now, before we can start to mess around with dimensional analysis we first need to extract the pixel size from the raw TIF image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SZ1Fff0OS3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tifffile.TiffFile(im_path) as tif:\n",
        "    \n",
        "    # Extract magnification data\n",
        "    mag = tif.sem_metadata['ap_mag'][1] \n",
        "    if type(mag) is str:  # Apply correction for \"k\" ex: mag = \"50 k\"\n",
        "        mag = float(mag.split(' ')[0]) * 1000\n",
        "    else:\n",
        "        mag = float(mag)\n",
        "\n",
        "    # Extract pixel size data\n",
        "    pixel_size = float(tif.sem_metadata['ap_pixel_size'][1])  # nm\n",
        "    if 'µm' in tif.sem_metadata['ap_pixel_size'][2]: # Correction for um\n",
        "        pixel_size *= 1000\n",
        "\n",
        "    # Extract tilt data\n",
        "    tilt = tif.sem_metadata['ap_tilt_angle'][1] # degrees\n",
        "    # tilt = tif.sem_metadata['ap_stage_at_t'][1]  # might be equivalent, not sure\n",
        "\n",
        "pixel_size_x = pixel_size  # nm\n",
        "pixel_size_y = pixel_size / np.cos(np.deg2rad(tilt))  # nm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BfeJGkdJczU",
        "colab_type": "text"
      },
      "source": [
        "Let's put the output into a handy Pandas Dataframe before any more processing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuYsqm19M6Tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define data structure\n",
        "data = { 'class':[],\n",
        "         'class_num':[],\n",
        "         'score':[],\n",
        "         'bbox':[],\n",
        "         'bbox_centre':[],\n",
        "         'height':[],\n",
        "         'width':[],\n",
        "         'mask':[],\n",
        "         'area':[],\n",
        "         'area_bbox':[]}\n",
        "\n",
        "# Loop over all objects\n",
        "for i in range(len(outputs[\"instances\"])):\n",
        "  \n",
        "  data['class'].append(inv_class_dict[str(cl[i]+1)])\n",
        "  data['class_num'].append(cl[i])\n",
        "\n",
        "  data['score'].append(s[i])\n",
        "\n",
        "  data['bbox'].append(b[i])\n",
        "  data['bbox_centre'].append(c[i])\n",
        "\n",
        "  h = (b[i,3] - b[i,1]) * pixel_size_y\n",
        "  data['height'].append(h)\n",
        "\n",
        "  w = (b[i,2] - b[i,0]) * pixel_size_x  \n",
        "  data['width'].append(w)\n",
        "\n",
        "  data['area_bbox'].append(w*h)\n",
        "\n",
        "  data['mask'].append(m[i])\n",
        "\n",
        "  data['area'].append(m[i].astype(int).sum() * pixel_size_x * pixel_size_y)\n",
        "\n",
        "df = pd.DataFrame.from_dict(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4BcMaqhfm5m",
        "colab_type": "text"
      },
      "source": [
        "Let's plot a simple bar graph of the number of objects in each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZgtF8eIfzAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(16,12))\n",
        "\n",
        "counts = df['class'].value_counts()\n",
        "total = sum(counts)\n",
        "values = [c/total*100 for c in counts]\n",
        "labels = list(counts.index)\n",
        "\n",
        "sns.barplot(x=labels, y=values) # height should be three times width);\n",
        "\n",
        "for i, v in enumerate(values):\n",
        "    plt.text(i, v + np.max(values)*0.01, f'{v:.1f}% ({counts[i]:.0f})', color='k', ha='center')\n",
        "\n",
        "plt.ylim([0, np.max(values)*(1.1)])\n",
        "plt.title('Growth Structure Yield (count)')\n",
        "plt.ylabel('Yield (%)')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC76PV5POVec",
        "colab_type": "text"
      },
      "source": [
        "Let's start with slit length/width."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pYmcv1AAk4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_slits = df[df['class']=='slit']\n",
        "\n",
        "print(f\"Mean slit width: {df_slits['height'].mean():.0f} +/- {df_slits['height'].std():.0f} nm\")\n",
        "print(f\"Mean slit length: {df_slits['width'].mean():.0f} +/- {df_slits['width'].std():.0f} nm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eP7FgTZdRrc",
        "colab_type": "text"
      },
      "source": [
        "Can use the slit bounding boxes to plot a comparison of total area fraction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3wXa4N9dc2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate slit area using the bounding box height (slit width) and image width\n",
        "# -> Avoids problems of weirdly-shaped slit segmentation masks\n",
        "slit_area = 0\n",
        "for h in df_slits['height']:\n",
        "  slit_area += h * (img_w * pixel_size_x)\n",
        "\n",
        "print(f\"slit area (bbox): {slit_area:.0f} nm2\")\n",
        "\n",
        "class_areas = []\n",
        "\n",
        "# Loop over all classes\n",
        "for c in range(len(class_dict)):\n",
        "  \n",
        "  df_filt = df[df['class_num']==c]\n",
        "\n",
        "  # There isn't any object with this class in the current image\n",
        "  if df_filt.size == 0:\n",
        "      print(f\"{inv_class_dict[str(c+1)]} area: 0 nm2\")\n",
        "      class_areas.append(0)\n",
        "      continue\n",
        "\n",
        "  # Stack all masks in this class together\n",
        "  overall_mask = df_filt['mask'].sum()\n",
        "\n",
        "  # This approach avoids double counting pixels if masks overlap with eachother\n",
        "  overall_mask = overall_mask.astype(bool).astype(int)\n",
        "\n",
        "  # Calculate area\n",
        "  area = overall_mask.sum() * pixel_size_x * pixel_size_y\n",
        "  print(f\"{inv_class_dict[str(c+1)]} area: {area:.0f} nm2\")\n",
        "  \n",
        "  # Add area to the areas list\n",
        "  class_areas.append(area)\n",
        "\n",
        "# Remove the \"slit\" class entry of the areas array since we will use the bbox value from above\n",
        "class_areas = class_areas[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tj73F-1kk79",
        "colab_type": "text"
      },
      "source": [
        "Now we can plot the total area of each class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xNvU3BgkJYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(16,12))\n",
        "\n",
        "values = [a/slit_area*100 for a in class_areas]\n",
        "labels = [inv_class_dict[str(c+1)] for c in range(1, len(class_dict))]\n",
        "\n",
        "sns.barplot(x=labels, y=values)\n",
        "\n",
        "for i, v in enumerate(values):\n",
        "    plt.text(i, v + np.max(values)*0.01, f'{v:.1f}%\\n({class_areas[i]:.0f} nm$^2$)', color='k', ha='center')\n",
        "\n",
        "plt.ylim([0, np.max(values)*(1.1)])\n",
        "plt.title('Growth Structure Yield (% of slit area)')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35ZWeKj4ltnf",
        "colab_type": "text"
      },
      "source": [
        "Then we can also look at nanomembrane dimensions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxiCmPuOGDTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_nms = df[df['class']=='nanomembrane']\n",
        "print(f\"Mean nanomembrane width: {df_nms['height'].mean():.0f} +/- {df_nms['height'].std():.0f} nm\")\n",
        "print(f\"Mean nanomembrane length: {df_nms['width'].mean():.0f} +/- {df_nms['width'].std():.0f} nm\")\n",
        "print(f\"Max nanomembrane length: {df_nms['width'].max():.0f} nm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u0o3NxalsmE",
        "colab_type": "text"
      },
      "source": [
        "If we want to compare the dimensions of all classes we can define a handy plotting function that we then use to plot different values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvafpCirCpiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a helper function for easy box plotting\n",
        "def make_box_plot(dat, x, x_lab):\n",
        "  # Create figure\n",
        "  fig = plt.figure(figsize=(12,8))\n",
        "\n",
        "  # Plot the orbital period with horizontal boxes\n",
        "  ax = sns.boxplot(x=x, y='class', data=dat, whis=[0, 100], palette=\"vlag\")\n",
        "  ax.set(xlim=(0, dat[x].max()*1.2))\n",
        "  ax.xaxis.grid(True)\n",
        "\n",
        "  # Add in points to show each observation\n",
        "  g = sns.swarmplot(x=x, y='class', data=dat, size=5, color=\".3\", linewidth=0)\n",
        "\n",
        "  # Tweak the visual presentation\n",
        "  sns.despine(trim=True, left=True)\n",
        "  plt.xlabel(x_lab)\n",
        "  plt.ylabel(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNMWym48DUgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Filter dataframe to exclude the slits, plot the data\n",
        "df_no_slit = df[df['class']!='slit']\n",
        "make_box_plot(df_no_slit,'height','Width (nm)');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUixzmyUaf2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Filter dataframe to exclude the slits, plot the data\n",
        "df_no_slit = df[df['class']!='slit']\n",
        "make_box_plot(df_no_slit,'width','Length (nm)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUblT0uZYEGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Filter dataframe to exclude the slits, plot the data\n",
        "df_no_slit = df[df['class']!='slit']\n",
        "make_box_plot(df_no_slit,'area','Area (nm$^2$)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcTnXUXFbV2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot a scatter plot of growth structure length vs width to try and see some trends\n",
        "fig = plt.figure(figsize=(12,8))\n",
        "ax = sns.scatterplot(x=\"width\", y=\"height\", hue=\"class\", style=\"class\", s=50, data=df_no_slit)\n",
        "ax.grid()\n",
        "ax.set(xlabel='Length (nm)')\n",
        "ax.set(ylabel='Width (nm)')\n",
        "\n",
        "# Add a horizontal line to represent median slit width\n",
        "ax.axhline(df_slits['height'].median(), ls='--', color='r')\n",
        "ax.text(0, df_slits['height'].median()*1.02, \"Median Slit Width\", color='r');"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}