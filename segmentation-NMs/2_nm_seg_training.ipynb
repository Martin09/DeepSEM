{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NM Segmentation 2: Model Definition and Training",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Martin09/DeepSEM/blob/master/segmentation-NMs/2_nm_seg_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHnVupBBn9eR",
        "colab_type": "text"
      },
      "source": [
        "# 2 - Model definition, training and saving\n",
        "In this notebook we will:\n",
        "1. Load and prepare our dataset.\n",
        "2. Create and configure a pre-trained model from the detectron2 model zoo. \n",
        "3. Train our custom model on our dataset of labelled SEM images. \n",
        "4. Perform inference to test our model.\n",
        "5. Save the model to a file for later use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFmdTLrqZfr3",
        "colab_type": "text"
      },
      "source": [
        "First, let's check that we are running a GPU instance of Colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU5aaqXsKgU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime -> \"Change runtime type\" menu to enable GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MODK1B7pfEv",
        "colab_type": "text"
      },
      "source": [
        "If you see a prompt above to \"Change runtime type\" then you are not running a GPU instance. Follow the instructions above to enable the GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII",
        "colab_type": "text"
      },
      "source": [
        "## Install detectron2\n",
        "We will be using Facebook's [detectron2](https://github.com/facebookresearch/detectron2) library to train our model. First we need to install it and its dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4hmGYk1dL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install detectron2:\n",
        "!pip install detectron2==0.1.2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# Import some common libraries\n",
        "import numpy as np\n",
        "import os, cv2, random, json, datetime, time, urllib, pycocotools\n",
        "from glob import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.structures import BoxMode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjbUIhSxUdm_",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "In this section, we will train an existing detectron2 model on our labelled SEM image dataset that we prepared in [Notebook 1](https://colab.research.google.com/github/Martin09/DeepSEM/blob/master/segmentation-NWs/1_nw_seg_image_prep.ipynb) and labelled with [Labelbox](https://labelbox.com). We will use a custom labelled nanowire detection dataset which can be downloaded [here](https://github.com/Martin09/DeepSEM/raw/master/segmentation-NWs/datasets/WJ_NWs_D1-17-02-17-C_processed.zip). This dataset has been labelled with three classes: \n",
        "*   Droplet\n",
        "*   Nanowire\n",
        "*   Parasitic\n",
        "\n",
        "From this, we will train a custom image segmentation model from an existing model pre-trained on the COCO dataset, available in detectron2's model zoo.\n",
        "\n",
        "Note: the COCO dataset does not have any of these categories by default so we will have to perform transfer learning to get the model to detect them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFuJHciptkop",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 - Preparing our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri1rTb18zlEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the classes in our dataset\n",
        "class_dict = {'slit': '1',\n",
        "              'nanomembrane': '2',\n",
        "              'parasitic': '3',\n",
        "              'bottom_nucleus': '4',\n",
        "              'side_nucleus': '5',\n",
        "              'nanowire': '6',\n",
        "              'overgrowth': '7'}\n",
        "\n",
        "# Define some paths/constants that will be useful later\n",
        "root = Path('./DeepSEM/segmentation-NMs/')\n",
        "dataset_dir = root.joinpath('datasets')\n",
        "output_dir = root.joinpath('output')\n",
        "models_dir = root.joinpath('trained_models')\n",
        "\n",
        "github_url = 'https://github.com/Martin09/' + str(root).replace('/','/trunk/')\n",
        "\n",
        "imgs_zip = dataset_dir.joinpath('Nick_NMs_50kmag_png.zip')\n",
        "imgs_dir = dataset_dir.joinpath(imgs_zip.stem)\n",
        "\n",
        "labelbox_export = dataset_dir.joinpath('export-2020-06-16T09_29_47.338Z.json')\n",
        "\n",
        "test_dir = imgs_dir.joinpath('test')\n",
        "train_dir = imgs_dir.joinpath('train')\n",
        "\n",
        "dataset_root_name = 'nm_masks'\n",
        "train_name = dataset_root_name + '_train'\n",
        "test_name = dataset_root_name + '_test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qg7zSVOulkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Optional: Save everything to your own GoogleDrive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive/')\n",
        "# %cd \"/content/gdrive/My Drive/path/to/save/location\"\n",
        "\n",
        "# Clone just the relevant folder from the DeepSEM repo\n",
        "!rm -rf $root\n",
        "!apt install subversion\n",
        "!svn checkout $github_url $root\n",
        "\n",
        "# # Alternative: Clone whole DeepSEM repository\n",
        "# !rm -rf DeepSEM  # Remove folder if it already exists\n",
        "# !git clone https://github.com/Martin09/DeepSEM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FF1vtvEJtjK",
        "colab_type": "text"
      },
      "source": [
        "To make things easier, I have already prepared a labelled dataset and put it in a handy .zip file. Next, let's unzip this dataset to use it for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwipNFeNrCSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove existing images directory and unzip dataset\n",
        "!rm -rf $imgs_dir\n",
        "!unzip -o $imgs_zip -d $imgs_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQIA-znvtrQ_",
        "colab_type": "text"
      },
      "source": [
        "Alternatively, you can download and build up the dataset from a LabelBox JSON export file from scratch. The script below will build up the same file structure using a LabelBox JSON export file. Downloading takes about 30s/image, depending on size and number of segmentation masks.\n",
        "\n",
        "Note: Not sure why but the JSON export from Labelbox seems to have some duplicates (20 images online, 23 images in JSON file) so I had to devise a crude check according to the \"External ID\" (aka PNG file name) to get rid of them. Might be worth investigating this later.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEf8JUg-zlPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from urllib.error import HTTPError\n",
        "\n",
        "# # Remove existing images directory\n",
        "# !rm -rf $imgs_dir\n",
        "\n",
        "# # Load json data\n",
        "# with open(labelbox_export) as f:\n",
        "#     data = json.load(f)\n",
        "\n",
        "# # Empty list to store image names, keep only unique data\n",
        "# image_names = []\n",
        "# unique_data = []\n",
        "\n",
        "# # Loop over all the images, keep only unique image names\n",
        "# for img in data:\n",
        "#     # Check if unique\n",
        "#     if img['External ID'] not in image_names:\n",
        "#       unique_data.append(img)\n",
        "#       image_names.append(img['External ID'])\n",
        "#     else:\n",
        "#       print(f\"'{img['External ID']} is a duplicate'\")\n",
        "\n",
        "# data = unique_data\n",
        "\n",
        "# # Perform test/train split by random choice\n",
        "# n_images = len(data)\n",
        "# i_test = np.random.choice(list(range(n_images)), int(n_images*0.1)+1, replace=False)\n",
        "\n",
        "# # Define a small helper function to download images from Labelbox\n",
        "# def get_image(img_url):\n",
        "#   counter = 0\n",
        "#   while(True):\n",
        "#     try:\n",
        "#       counter += 1\n",
        "#       time.sleep(0.2)  # To not overload the LabelBox servers with requests\n",
        "#       image = Image.open(urllib.request.urlopen(img_url))\n",
        "#       return image\n",
        "#     except HTTPError:\n",
        "#       if counter > 10:\n",
        "#         print('Image download failed 10 times in a row!')\n",
        "#         raise\n",
        "\n",
        "# # Loop over all the images (one image per row)\n",
        "# for i, img in enumerate(tqdm(data, unit='image')):\n",
        "#     image_name = img['External ID']\n",
        "\n",
        "#     # Output image into test and train directories randomly\n",
        "#     if i in i_test:\n",
        "#         example_dest_dir = imgs_dir.joinpath('test/' + image_name.split(\".\")[0])\n",
        "#     else:\n",
        "#         example_dest_dir = imgs_dir.joinpath('train/' + image_name.split(\".\")[0])\n",
        "\n",
        "#     # If there are labels for this image, create a folder for it and save the image\n",
        "#     if img['Label']['objects'] and len(img['Label']['objects']) > 0:\n",
        "#         example_dest_dir.joinpath('images').mkdir(parents=True, exist_ok=True)\n",
        "#         image_url = img['Labeled Data']\n",
        "#         image = get_image(image_url)\n",
        "#         image.save(example_dest_dir.joinpath('images/' + image_name))\n",
        "    \n",
        "#     # For each label, download the mask PNG file from labelbox and save it to relevant path\n",
        "#     for label in img['Label']['objects']:\n",
        "#         mask_class = class_dict[label['value']]\n",
        "#         mask_name = label['featureId']\n",
        "#         mask_url = label['instanceURI']\n",
        "\n",
        "#         mask_dest_dir = example_dest_dir.joinpath('masks/' + mask_class)\n",
        "#         mask_dest_dir.mkdir(parents=True, exist_ok=True)\n",
        "#         mask = get_image(mask_url)\n",
        "#         mask.save(mask_dest_dir.joinpath(mask_name +'.png'), bit=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTFhn2GhBhTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Optional: download the dataset\n",
        "# from google.colab import files\n",
        "# %cd $imgs_dir\n",
        "# !rm -rf ../dataset.zip\n",
        "# !zip -r ../dataset.zip *\n",
        "# time.sleep(10) # Give it a bit of time to save the file\n",
        "# files.download(\"../dataset.zip\")\n",
        "# %cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk4gID50K03a",
        "colab_type": "text"
      },
      "source": [
        "###Calculate mean pixel intensity of dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IRGo8d0qkgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calcualte dataset mean pixel intensity\n",
        "images = list(train_dir.glob('*/images/*.png'))\n",
        "\n",
        "min_pixel_intensity = np.infty\n",
        "max_pixel_intensity = -np.infty\n",
        "mean_pixel_intensity = 0\n",
        "for img in images:\n",
        "    im = cv2.imread(str(img),cv2.IMREAD_GRAYSCALE)\n",
        "    min_pixel_intensity = min([np.min(im), min_pixel_intensity])\n",
        "    max_pixel_intensity = max([np.max(im), max_pixel_intensity])\n",
        "    mean_pixel_intensity += np.mean(im)\n",
        "mean_pixel_intensity /= len(images)\n",
        "\n",
        "print('The min pixel intesity is: {:.2f}'.format(min_pixel_intensity))\n",
        "print('The max pixel intesity is: {:.2f}'.format(max_pixel_intensity))\n",
        "print('The mean pixel intesity is: {:.2f}'.format(mean_pixel_intensity))\n",
        "mpi = float(mean_pixel_intensity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVJoOm6LVJwW",
        "colab_type": "text"
      },
      "source": [
        "Register the nanowire dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n",
        "Here, the dataset is in its custom format, therefore we write a function to parse it and prepare it into detectron2's standard format. See the tutorial for more details.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIbAM2pv-urF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
        "# from detectron2.data.datasets import register_coco_instances\n",
        "# register_coco_instances(\"my_dataset_train\", {}, \"json_annotation_train.json\", \"path/to/image/dir\")\n",
        "# register_coco_instances(\"my_dataset_test\", {}, \"json_annotation_test.json\", \"path/to/image/dir\")\n",
        "\n",
        "def get_bbox(msk):\n",
        "    rows = np.any(msk, axis=1)\n",
        "    cols = np.any(msk, axis=0)\n",
        "    ymin, ymax = np.where(rows)[0][[0, -1]]\n",
        "    xmin, xmax = np.where(cols)[0][[0, -1]]\n",
        "    return xmin, ymin, xmax, ymax\n",
        "\n",
        "def get_nw_mask_dicts_from_labelbox(folder):\n",
        "    dataset_dicts = []\n",
        "    for idx, img_file in enumerate(folder.glob('*/images/*.png')):    \n",
        "        record = {}\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"file_name\"] = str(img_file)\n",
        "        \n",
        "        height, width = cv2.imread(str(img_file)).shape[:2]\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width    \n",
        "\n",
        "        objs = []\n",
        "\n",
        "        for mask_file in img_file.parents[1].glob('masks/*/*.png'):\n",
        "            mask = cv2.imread(str(mask_file), cv2.IMREAD_GRAYSCALE)\n",
        "            mask = (mask/mask.max()).astype(np.uint8)  # Convert to integer mask\n",
        "            try:\n",
        "                obj = {\n",
        "                    \"bbox\": list(get_bbox(mask)),\n",
        "                    \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                    \"segmentation\": pycocotools.mask.encode(np.asarray(mask, order=\"F\")),\n",
        "                    \"category_id\": int(mask_file.parent.stem)-1,\n",
        "                }\n",
        "            except IndexError: # Can happen if we have an emtpy mask and try to find its bbox, for example\n",
        "                continue\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpmcUJW7XnQL",
        "colab_type": "text"
      },
      "source": [
        "Now we register the train and test datasets in detectron2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "due3FwoEPdD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "DatasetCatalog.clear()\n",
        "\n",
        "for d in [train_dir, test_dir]:\n",
        "    DatasetCatalog.register(dataset_root_name + '_' + d.stem, lambda d=d: get_nw_mask_dicts_from_labelbox(d))\n",
        "    MetadataCatalog.get(dataset_root_name + '_' + d.stem).set(thing_classes=list(class_dict))\n",
        "nanowire_metadata = MetadataCatalog.get(train_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ljbWTX0Wi8E",
        "colab_type": "text"
      },
      "source": [
        "To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkNbUzUOLYf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dicts = get_nw_mask_dicts_from_labelbox(train_dir)\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=nanowire_metadata, scale=1.0)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqXIXXhW8dA",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 - Model definition\n",
        "\n",
        "Now, we will load a COCO-pretrained RR50-FPN Mask R-CNN model from the [detectron2 model zoo](https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md). We will then modify its configuration settings in order to adapt it for transfer learning on our SEM dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7unkuuiqLdqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = get_cfg()\n",
        "cfg.OUTPUT_DIR = str(output_dir.joinpath(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')))  # Timestamp output folder\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.INPUT.MASK_FORMAT='bitmask'\n",
        "cfg.DATASETS.TRAIN = (train_name,)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 8\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 8\n",
        "cfg.SOLVER.BASE_LR = 0.05  # learning rate\n",
        "cfg.SOLVER.MAX_ITER = 100  # 100 here is for proof of concept, will want to increase this to 10-20k for final model\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 5000  # Save a checkpoint after every this number of iterations\n",
        "\n",
        "# Learning rate warmup and decay\n",
        "cfg.SOLVER.WARMUP_FACTOR = 1/1000.  # Learning starts at BASE_LR * WU_FACTOR\n",
        "cfg.SOLVER.WARMUP_ITERS = 1000  # Number of iterations for warm-up phase\n",
        "cfg.SOLVER.WARMUP_METHOD = \"linear\"\n",
        "cfg.SOLVER.GAMMA = 0.5\n",
        "# cfg.SOLVER.STEPS = (100,200,300,)  # List of iteration numbers at which to decrease learning rate by factor GAMMA.\n",
        "cfg.SOLVER.STEPS = tuple(range(0,cfg.SOLVER.MAX_ITER,2000)) # Decrease LR every 1000 steps\n",
        "\n",
        "# Don't scale the input images\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = (0,)  # Keep these data types or might run into issues during inference when loading config file\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = 99999  # Keep these data types or might run into issues during inference when loading config file\n",
        "\n",
        "cfg.MODEL.PIXEL_MEAN = [mpi, mpi, mpi] \n",
        "cfg.MODEL.PIXEL_STD = [1.0, 1.0, 1.0]\n",
        "cfg.MODEL.ROI_HEADS.IOU_THRESHOLDS = [0.5] # Intersection over union threshold\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(class_dict) # We have three classification classes "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbzRZ-svE8RQ",
        "colab_type": "text"
      },
      "source": [
        "We can start up tensorboard to monitor training progress in realtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdRglxBzdvel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "# %reload_ext tensorboard\n",
        "%tensorboard --logdir $output_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPOsrG-zKrmJ",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 - Training\n",
        "It takes ~2 minutes to train 100 iterations on Colab Pro's Tesla P100 GPUs and a bit longer on Colab's free Tesla K80 GPUs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y11fbM2XDCFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start training\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqe3k68MQwGI",
        "colab_type": "text"
      },
      "source": [
        "Hopefully, during training you should start to see the `total_loss` decreasing over time as the model learns. Initially, the learning rate (`lr`) will increase during the warm-up stage for 1000 iterations. After which it will be halved every 1000 iterations until the end of training. These settings can all be changed in the config (`cgf.XX = X`) definitions above. As a proof of concept, I have set `cfg.SOLVER.MAX_ITER=100` but you should increase this to 1000 or even >10000 to achieve the best performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uhltvl2uRDvx"
      },
      "source": [
        "## 2.4 - Inference with a trained model\n",
        "Now, let's run inference with the trained model on the test dataset. First, let's create a predictor using the model we just trained:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya5nEuMELeq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # Set the testing threshold for this model\n",
        "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.2     # Non-max supression threshold\n",
        "cfg.DATASETS.TEST = (test_name, )\n",
        "cfg.TEST.DETECTIONS_PER_IMAGE = 200\n",
        "cfg.INPUT.MIN_SIZE_TEST = 0\n",
        "cfg.INPUT.MAX_SIZE_TEST = 99999\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWq1XHfDWiXO",
        "colab_type": "text"
      },
      "source": [
        "Then, we randomly a few test samples to visualize the prediction results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5LhISJqWXgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = get_nw_mask_dicts_from_labelbox(test_dir)\n",
        "for d in random.sample(dataset_dicts, 2):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=nanowire_metadata, \n",
        "                   scale=1.5, \n",
        "                  #  instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEiAJuezRRkY",
        "colab_type": "text"
      },
      "source": [
        "We can see that already, even with relatively few training iterations, thanks to transfer learning on a pre-trained network, the model already achieves quite good performance! As you train for longer, the predictions will get even more accurate. At >10k training iterations the model should approach human-level performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz4eDaNo8fBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Check the outputs of the neural network manually:\n",
        "# outputs[\"instances\"].pred_boxes\n",
        "# outputs[\"instances\"].scores\n",
        "# outputs[\"instances\"].pred_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kblA1IyFvWbT",
        "colab_type": "text"
      },
      "source": [
        "We can also evaluate its performance using AP metric implemented in COCO API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9tECBQCvMv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ## Not working yet\n",
        "# from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "# from detectron2.data import build_detection_test_loader\n",
        "# evaluator = COCOEvaluator(train_name, cfg, False)#, output_dir=output_dir)\n",
        "# test_loader = build_detection_test_loader(cfg, train_name\n",
        "# inference_on_dataset(trainer.model, test_loader, evaluator)\n",
        "# # another equivalent way is to use trainer.test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkAjalDpa6na",
        "colab_type": "text"
      },
      "source": [
        "## 2.5 - Saving the trained model\n",
        "Now let's save our final model for safe keeping to use it in the next notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2SCraQSca-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_source = cfg.OUTPUT_DIR + '/model_final.pth'\n",
        "model_name = 'nm_seg_it'+str(trainer.iter)+'_lossX.XXX.yaml'\n",
        "model_dest = models_dir.joinpath(model_name)\n",
        "\n",
        "# Move weights file to \"trained_models\" folder and update the config file accordingly\n",
        "weights_dest = model_dest.parent.joinpath(model_dest.stem + '.pth')\n",
        "!cp $weights_source $weights_dest\n",
        "cfg.MODEL.WEIGHTS = str(weights_dest)\n",
        "\n",
        "# Save the config file alongside the weights file\n",
        "confi_dest = model_dest\n",
        "with open(confi_dest, \"w\") as text_file:\n",
        "    text_file.write(cfg.dump())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZrP2DAEia8d",
        "colab_type": "text"
      },
      "source": [
        "## A final note on overfitting\n",
        "In this example we are only monitoring the training loss as a function of iterations. This has the disadvantage that we do not know if our model is over-fitting to our training set. In this simple application we don't worry about overfitting too much, especially as the model seems to perform well on the test set after training. However, to achieve the best possible performance, we should create a small third dataset called a validation set with which we periodically estimate the performance of the model during training. Training should then be stopped when validation loss stops decreasing to prevent overfitting on the training set.\n",
        "\n",
        "Next, in [Notebook 3](https://colab.research.google.com/github/Martin09/DeepSEM/blob/master/segmentation-NMs/3_nm_seg_inference.ipynb), let's see how we can apply our trained model on raw SEM images and extract some important growth information from them!"
      ]
    }
  ]
}